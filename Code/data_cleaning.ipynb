{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5469339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fb6b7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from final_output.json\n",
      "\n",
      "--- Processing 'train' section ---\n",
      "Loaded 16659 records into a DataFrame.\n",
      "\n",
      "Checking field: 'face_embedding'\n",
      "  Records with explicit null/missing key (face_embedding is None/NaN): 0\n",
      "  Records with empty list (face_embedding is []): 0\n",
      "  Records with face_embedding being null/missing OR empty: 0 out of 16659\n",
      "\n",
      "Checking field: 'pose_embedding'\n",
      "  Records with explicit null/missing key (pose_embedding is None/NaN): 9\n",
      "  Records with empty list (pose_embedding is []): 0\n",
      "  Records with pose_embedding being null/missing OR empty: 9 out of 16659\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "--- Processing 'test' section ---\n",
      "Loaded 3544 records into a DataFrame.\n",
      "\n",
      "Checking field: 'face_embedding'\n",
      "  Records with explicit null/missing key (face_embedding is None/NaN): 0\n",
      "  Records with empty list (face_embedding is []): 0\n",
      "  Records with face_embedding being null/missing OR empty: 0 out of 3544\n",
      "\n",
      "Checking field: 'pose_embedding'\n",
      "  Records with explicit null/missing key (pose_embedding is None/NaN): 2\n",
      "  Records with empty list (pose_embedding is []): 0\n",
      "  Records with pose_embedding being null/missing OR empty: 2 out of 3544\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "--- Processing 'val' section ---\n",
      "Loaded 3503 records into a DataFrame.\n",
      "\n",
      "Checking field: 'face_embedding'\n",
      "  Records with explicit null/missing key (face_embedding is None/NaN): 0\n",
      "  Records with empty list (face_embedding is []): 0\n",
      "  Records with face_embedding being null/missing OR empty: 0 out of 3503\n",
      "\n",
      "Checking field: 'pose_embedding'\n",
      "  Records with explicit null/missing key (pose_embedding is None/NaN): 2\n",
      "  Records with empty list (pose_embedding is []): 0\n",
      "  Records with pose_embedding being null/missing OR empty: 2 out of 3503\n",
      "\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os # To check if the file exists\n",
    "import json\n",
    "# Assuming your full JSON data is in a file named 'your_dataset.json'\n",
    "# This file should contain top-level keys like \"train\", \"test\", \"valid\"\n",
    "file_path = 'final_output.json'\n",
    "\n",
    "# Names of the embedding fields to check\n",
    "embedding_fields = ['face_embedding', 'pose_embedding']\n",
    "\n",
    "# Load the full JSON data\n",
    "try:\n",
    "    with open(file_path, 'r') as f:\n",
    "        full_data = json.load(f)\n",
    "\n",
    "    print(f\"Successfully loaded data from {file_path}\\n\")\n",
    "\n",
    "    # Process each section (train, test, valid)\n",
    "    for section_name in ['train', 'test', 'val']:\n",
    "        if section_name in full_data and isinstance(full_data[section_name], list):\n",
    "            print(f\"--- Processing '{section_name}' section ---\")\n",
    "            section_data = full_data[section_name]\n",
    "\n",
    "            if not section_data:\n",
    "                print(f\"'{section_name}' section is empty. No records to check.\\n\")\n",
    "                continue\n",
    "\n",
    "            # Convert the list of records to a DataFrame\n",
    "            df_section = pd.DataFrame(section_data)\n",
    "            print(f\"Loaded {len(df_section)} records into a DataFrame.\")\n",
    "\n",
    "            # Check each embedding field\n",
    "            for field in embedding_fields:\n",
    "                print(f\"\\nChecking field: '{field}'\")\n",
    "                if field in df_section.columns:\n",
    "                    # Check for explicit nulls (None/NaN)\n",
    "                    is_explicitly_null = df_section[field].isna()\n",
    "                    count_explicitly_null = is_explicitly_null.sum()\n",
    "\n",
    "                    # Check for empty lists (only if the value is a list)\n",
    "                    # Need to handle potential None/NaN values in the apply function\n",
    "                    is_empty_list = df_section[field].apply(\n",
    "                        lambda x: isinstance(x, list) and len(x) == 0\n",
    "                    )\n",
    "                    count_empty_list = is_empty_list.sum()\n",
    "\n",
    "                    # Check for cases where the key might be missing (values are NaN if not explicitly present)\n",
    "                    # Note: pd.read_json often puts NaN for missing keys when records have different structures\n",
    "                    # We can check isna() again, which will catch NaNs from missing keys too\n",
    "                    is_missing_key_or_null = df_section[field].isna()\n",
    "                    # Recalculate explicit null count including missing keys handled as NaN\n",
    "                    count_missing_key_or_null = is_missing_key_or_null.sum() - count_empty_list # Subtract empty lists already counted\n",
    "\n",
    "                    # Combine check: is it explicitly null/missing OR an empty list?\n",
    "                    is_null_or_empty = is_explicitly_null | is_empty_list\n",
    "                    count_null_or_empty = is_null_or_empty.sum()\n",
    "\n",
    "\n",
    "                    print(f\"  Records with explicit null/missing key ({field} is None/NaN): {count_missing_key_or_null}\")\n",
    "                    print(f\"  Records with empty list ({field} is []): {count_empty_list}\")\n",
    "                    print(f\"  Records with {field} being null/missing OR empty: {count_null_or_empty} out of {len(df_section)}\")\n",
    "\n",
    "                    # Optional: Display rows where the field is null/empty\n",
    "                    # if count_null_or_empty > 0:\n",
    "                    #     print(f\"  Sample rows where '{field}' is null/empty:\")\n",
    "                    #     print(df_section[is_null_or_empty])\n",
    "\n",
    "\n",
    "                else:\n",
    "                    print(f\"  Field '{field}' not found in this section's DataFrame.\")\n",
    "                    # If the column doesn't exist, maybe all records are missing this key?\n",
    "                    # Check if the original json data confirms this\n",
    "                    # (More advanced check, simplified here by just reporting)\n",
    "                    all_missing = all(field not in record for record in section_data)\n",
    "                    if all_missing:\n",
    "                         print(f\"  Note: The field '{field}' appears to be missing from ALL records in the '{section_name}' section in the original JSON.\")\n",
    "\n",
    "\n",
    "            print(f\"\\n{'-'*len(f'--- Processing {section_name} section ---')}\\n\")\n",
    "\n",
    "        elif section_name not in full_data:\n",
    "            print(f\"Warning: Section '{section_name}' not found in the JSON data.\\n\")\n",
    "        else:\n",
    "            print(f\"Warning: Section '{section_name}' in JSON is not a list of records (type: {type(full_data[section_name]).__name__}). Skipping.\\n\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Could not decode JSON from '{file_path}'. Please check the file format.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8502e060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from final_output.json\n",
      "\n",
      "--- Processing and Cleaning 'train' section ---\n",
      "'train': Initial records = 16659\n",
      "'train': Removed 9 records with missing/empty embeddings. Remaining records = 16650\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Processing and Cleaning 'test' section ---\n",
      "'test': Initial records = 3544\n",
      "'test': Removed 2 records with missing/empty embeddings. Remaining records = 3542\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Processing and Cleaning 'val' section ---\n",
      "'val': Initial records = 3503\n",
      "'val': Removed 2 records with missing/empty embeddings. Remaining records = 3501\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Saving cleaned data to check.json...\n",
      "Saving complete.\n",
      "Cleaned data saved to 'check.json'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to your input JSON file\n",
    "input_file_path = 'final_output.json'\n",
    "\n",
    "# Path where the cleaned output JSON file will be saved\n",
    "output_file_path = 'check.json'\n",
    "\n",
    "# Names of the embedding fields that, if missing/empty, should cause the record to be eliminated\n",
    "embedding_fields_for_elimination = ['face_embedding', 'pose_embedding']\n",
    "\n",
    "# Expected top-level sections in your JSON file (adjust if you have different keys)\n",
    "sections_to_process = ['train', 'test', 'val']\n",
    "\n",
    "# --- End Configuration ---\n",
    "\n",
    "\n",
    "# Dictionary to store the cleaned dataframes for each section\n",
    "cleaned_dataframes = {}\n",
    "full_data = {} # Dictionary to hold the data loaded from the input JSON\n",
    "\n",
    "# Load the full JSON data\n",
    "try:\n",
    "    if not os.path.exists(input_file_path):\n",
    "        raise FileNotFoundError(f\"Input file not found at: {input_file_path}\")\n",
    "\n",
    "    with open(input_file_path, 'r') as f:\n",
    "        full_data = json.load(f)\n",
    "\n",
    "    print(f\"Successfully loaded data from {input_file_path}\\n\")\n",
    "\n",
    "    # Process each specified section\n",
    "    for section_name in sections_to_process:\n",
    "        if section_name in full_data and isinstance(full_data[section_name], list):\n",
    "            print(f\"--- Processing and Cleaning '{section_name}' section ---\")\n",
    "            section_data = full_data[section_name]\n",
    "\n",
    "            if not section_data:\n",
    "                print(f\"'{section_name}' section is empty. No records to process.\\n\")\n",
    "                cleaned_dataframes[section_name] = pd.DataFrame() # Store an empty DataFrame\n",
    "                continue\n",
    "\n",
    "            # Convert the list of records to a DataFrame\n",
    "            df_section = pd.DataFrame(section_data)\n",
    "            initial_rows = len(df_section)\n",
    "            print(f\"'{section_name}': Initial records = {initial_rows}\")\n",
    "\n",
    "            # --- Identify rows to keep (where fields are NOT null/missing AND NOT empty) ---\n",
    "            # Start with a condition that keeps all rows (all True) for this section's index\n",
    "            rows_to_keep_condition = pd.Series(True, index=df_section.index)\n",
    "\n",
    "            for field in embedding_fields_for_elimination:\n",
    "                if field in df_section.columns:\n",
    "                    # A value is considered 'good' for filtering if it's NOT pd.isna() AND (it's NOT a list OR it's a list with length > 0)\n",
    "                    # Handle cases where the value might not be a list before checking length\n",
    "                    is_field_good = ~df_section[field].isna() & \\\n",
    "                                    ( ~df_section[field].apply(lambda x: isinstance(x, list)) | \\\n",
    "                                      df_section[field].apply(lambda x: isinstance(x, list) and len(x) > 0) )\n",
    "\n",
    "                    # Update the overall 'rows_to_keep_condition'\n",
    "                    # A row is kept only if it satisfied the 'good' condition for *all* checked fields so far\n",
    "                    rows_to_keep_condition = rows_to_keep_condition & is_field_good\n",
    "\n",
    "                    # Optional: Report how many rows meet the good condition for this field\n",
    "                    # print(f\"  - {is_field_good.sum()} rows in '{section_name}' have valid (not null/empty) '{field}'.\")\n",
    "\n",
    "                else:\n",
    "                     print(f\"  - Warning: Field '{field}' not found in '{section_name}' section DataFrame. Records cannot be filtered based on '{field}' in this section.\")\n",
    "                     # Decide how to handle a missing column if it's critical:\n",
    "                     # Option A (Remove all rows if a critical column is missing):\n",
    "                     # print(f\"  - Treating missing critical field '{field}' as condition to remove all rows in '{section_name}'.\")\n",
    "                     # rows_to_keep_condition = pd.Series(False, index=df_section.index)\n",
    "                     # break # Exit the inner loop as all rows are marked for removal\n",
    "                     # Option B (Just skip filtering for this field in this section - current behavior):\n",
    "                     pass\n",
    "\n",
    "\n",
    "            # Filter the DataFrame using the combined condition: keep rows where rows_to_keep_condition is True\n",
    "            df_section_cleaned = df_section[rows_to_keep_condition].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
    "\n",
    "            removed_rows = initial_rows - len(df_section_cleaned)\n",
    "            print(f\"'{section_name}': Removed {removed_rows} records with missing/empty embeddings. Remaining records = {len(df_section_cleaned)}\")\n",
    "\n",
    "            # Store the cleaned DataFrame in the dictionary\n",
    "            cleaned_dataframes[section_name] = df_section_cleaned\n",
    "\n",
    "            print(f\"\\n{'-'*50}\\n\")\n",
    "\n",
    "        elif section_name not in full_data:\n",
    "            print(f\"Warning: Section '{section_name}' not found in the JSON data. Skipping.\\n\")\n",
    "        else:\n",
    "            print(f\"Warning: Section '{section_name}' in JSON is not a list of records (type: {type(full_data[section_name]).__name__}). Skipping.\\n\")\n",
    "\n",
    "    # --- Assemble the final output JSON structure ---\n",
    "    final_output_data = {}\n",
    "    for section_name in sections_to_process:\n",
    "        if section_name in cleaned_dataframes:\n",
    "             # Convert cleaned DataFrame back to a list of dictionaries (JSON structure)\n",
    "            final_output_data[section_name] = cleaned_dataframes[section_name].to_dict(orient='records')\n",
    "        elif section_name in full_data:\n",
    "             # If a section existed but wasn't a list or was empty, include it as it was\n",
    "             final_output_data[section_name] = full_data[section_name]\n",
    "        # If a section wasn't in full_data at all, it won't be added to final_output_data\n",
    "\n",
    "    # --- Save the cleaned data to a new JSON file ---\n",
    "    print(f\"Saving cleaned data to {output_file_path}...\")\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        json.dump(final_output_data, f, indent=4) # Use indent for pretty printing\n",
    "\n",
    "    print(\"Saving complete.\")\n",
    "    print(f\"Cleaned data saved to '{output_file_path}'.\")\n",
    "\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Could not decode JSON from '{input_file_path}'. Please check the file format.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a91857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
