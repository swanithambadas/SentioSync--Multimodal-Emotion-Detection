{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc86203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4373362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, json_path, split=\"train\"):\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        self.samples = []\n",
    "        for item in data.get(split, []):\n",
    "            face = item.get(\"face_embedding\")\n",
    "            pose = item.get(\"pose_embedding\")\n",
    "            label = item.get(\"multi_hot\")\n",
    "            if face is None or pose is None or label is None:\n",
    "                continue\n",
    "            self.samples.append((face, pose, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        face, pose, label = self.samples[idx]\n",
    "        return (\n",
    "            torch.tensor(face, dtype=torch.float32),\n",
    "            torch.tensor(pose, dtype=torch.float32),\n",
    "            torch.tensor(label, dtype=torch.float32),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e78cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, threshold=0.5):\n",
    "    y_pred_bin = (y_pred > threshold).astype(int)\n",
    "    accuracy  = accuracy_score(y_true, y_pred_bin)\n",
    "    precision = precision_score(y_true, y_pred_bin, average='micro', zero_division=0)\n",
    "    recall    = recall_score(y_true, y_pred_bin, average='micro', zero_division=0)\n",
    "    f1        = f1_score(y_true, y_pred_bin, average='micro', zero_division=0)\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_labels, all_preds = [], []\n",
    "    for face, pose, label in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "        face, pose, label = face.to(device), pose.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(face, pose)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        all_labels.append(label.cpu().numpy())\n",
    "        all_preds.append(output.detach().cpu().numpy())\n",
    "    y_true = np.vstack(all_labels)\n",
    "    y_pred = np.vstack(all_preds)\n",
    "    return total_loss / len(dataloader), compute_metrics(y_true, y_pred)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, mode=\"Validation\"):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_labels, all_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for face, pose, label in tqdm(dataloader, desc=mode, leave=False):\n",
    "            face, pose, label = face.to(device), pose.to(device), label.to(device)\n",
    "            output = model(face, pose)\n",
    "            loss = criterion(output, label)\n",
    "            total_loss += loss.item()\n",
    "            all_labels.append(label.cpu().numpy())\n",
    "            all_preds.append(output.cpu().numpy())\n",
    "    y_true = np.vstack(all_labels)\n",
    "    y_pred = np.vstack(all_preds)\n",
    "    return total_loss / len(dataloader), compute_metrics(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e2adac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device,\n",
    "                epochs=20, save_path=\"best_vit_crossattn.pt\"):\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        train_loss, train_metrics = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss,   val_metrics   = evaluate(model, val_loader,   criterion, device, mode=\"Validation\")\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f} | \"\n",
    "              f\"Acc: {train_metrics['accuracy']:.4f} | \"\n",
    "              f\"Prec: {train_metrics['precision']:.4f} | \"\n",
    "              f\"Rec: {train_metrics['recall']:.4f} | \"\n",
    "              f\"F1: {train_metrics['f1']:.4f}\")\n",
    "        print(f\" Val  Loss: {val_loss:.4f} | \"\n",
    "              f\"Acc: {val_metrics['accuracy']:.4f} | \"\n",
    "              f\"Prec: {val_metrics['precision']:.4f} | \"\n",
    "              f\"Rec: {val_metrics['recall']:.4f} | \"\n",
    "              f\"F1: {val_metrics['f1']:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"→ Best model saved.\")\n",
    "\n",
    "def test_model(model, test_loader, criterion, device, save_path=\"best_vit_crossattn.pt\"):\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    test_loss, test_metrics = evaluate(model, test_loader, criterion, device, mode=\"Test\")\n",
    "    print(f\"\\nTest Loss: {test_loss:.4f} | \"\n",
    "          f\"Acc: {test_metrics['accuracy']:.4f} | \"\n",
    "          f\"Prec: {test_metrics['precision']:.4f} | \"\n",
    "          f\"Rec: {test_metrics['recall']:.4f} | \"\n",
    "          f\"F1: {test_metrics['f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28d16fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkedCrossAttnViT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        face_dim: int = 512,\n",
    "        face_chunks: int = 8,\n",
    "        pose_dim: int = 34,\n",
    "        pose_chunks: int = 2,\n",
    "        hidden_dim: int = 256,\n",
    "        num_classes: int = 7,\n",
    "        n_heads: int = 4,\n",
    "        face_layers: int = 2,\n",
    "        pose_layers: int = 2,\n",
    "        fusion_layers: int = 4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert face_dim % face_chunks == 0, \"face_dim must be divisible by face_chunks\"\n",
    "        assert pose_dim % pose_chunks == 0, \"pose_dim must be divisible by pose_chunks\"\n",
    "        self.face_chunks = face_chunks\n",
    "        self.pose_chunks = pose_chunks\n",
    "        self.f_chunk_size = face_dim // face_chunks\n",
    "        self.p_chunk_size = pose_dim // pose_chunks\n",
    "\n",
    "        self.face_proj = nn.Linear(self.f_chunk_size, hidden_dim)\n",
    "        self.pose_proj = nn.Linear(self.p_chunk_size, hidden_dim)\n",
    "\n",
    "        fe = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=n_heads, batch_first=True)\n",
    "        self.face_enc = nn.TransformerEncoder(fe, num_layers=face_layers)\n",
    "        pe = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=n_heads, batch_first=True)\n",
    "        self.pose_enc = nn.TransformerEncoder(pe, num_layers=pose_layers)\n",
    "\n",
    "        self.f2p_attn = nn.MultiheadAttention(hidden_dim, n_heads, batch_first=True)\n",
    "        self.p2f_attn = nn.MultiheadAttention(hidden_dim, n_heads, batch_first=True)\n",
    "\n",
    "        total_tokens = 1 + face_chunks + pose_chunks\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, hidden_dim))\n",
    "        self.pos_emb = nn.Parameter(torch.randn(1, total_tokens, hidden_dim))\n",
    "\n",
    "        fu = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=n_heads, batch_first=True)\n",
    "        self.fusion_enc = nn.TransformerEncoder(fu, num_layers=fusion_layers)\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim // 2, num_classes),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, face: torch.Tensor, pose: torch.Tensor) -> torch.Tensor:\n",
    "        B = face.size(0)\n",
    "\n",
    "        f = face.view(B, self.face_chunks, self.f_chunk_size)\n",
    "        f = self.face_proj(f)\n",
    "        f = self.face_enc(f)\n",
    "\n",
    "        p = pose.view(B, self.pose_chunks, self.p_chunk_size)\n",
    "        p = self.pose_proj(p)\n",
    "        p = self.pose_enc(p)\n",
    "\n",
    "        f2p, _ = self.f2p_attn(query=f, key=p, value=p)\n",
    "        f = f + f2p\n",
    "        p2f, _ = self.p2f_attn(query=p, key=f, value=f)\n",
    "        p = p + p2f\n",
    "\n",
    "        cls = self.cls_token.expand(B, -1, -1)\n",
    "        seq = torch.cat([cls, f, p], dim=1) + self.pos_emb\n",
    "\n",
    "        fused = self.fusion_enc(seq)\n",
    "        cls_out = fused[:, 0]\n",
    "        return self.mlp_head(cls_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dba1287",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = \"final_annotations.json\"\n",
    "batch_size = 32\n",
    "epochs     = 20\n",
    "save_path  = \"best_vit_chunked_crossattn.pt\"\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_ds = EmotionDataset(json_path, split=\"train\")\n",
    "val_ds   = EmotionDataset(json_path, split=\"val\")\n",
    "test_ds  = EmotionDataset(json_path, split=\"test\")\n",
    "\n",
    "train_ld = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_ld   = DataLoader(val_ds,   batch_size=batch_size)\n",
    "test_ld  = DataLoader(test_ds,  batch_size=batch_size)\n",
    "\n",
    "model     = ChunkedCrossAttnViT().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cc3646c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2723 | Acc: 0.5674 | Prec: 0.8155 | Rec: 0.6174 | F1: 0.7028\n",
      " Val  Loss: 0.2601 | Acc: 0.5636 | Prec: 0.8207 | Rec: 0.6125 | F1: 0.7015\n",
      "→ Best model saved.\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2583 | Acc: 0.5639 | Prec: 0.8135 | Rec: 0.6245 | F1: 0.7066\n",
      " Val  Loss: 0.2654 | Acc: 0.5638 | Prec: 0.8184 | Rec: 0.6135 | F1: 0.7013\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2552 | Acc: 0.5640 | Prec: 0.8098 | Rec: 0.6301 | F1: 0.7087\n",
      " Val  Loss: 0.2565 | Acc: 0.5658 | Prec: 0.8187 | Rec: 0.6168 | F1: 0.7035\n",
      "→ Best model saved.\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2510 | Acc: 0.5638 | Prec: 0.8103 | Rec: 0.6347 | F1: 0.7118\n",
      " Val  Loss: 0.2565 | Acc: 0.5430 | Prec: 0.7678 | Rec: 0.6735 | F1: 0.7176\n",
      "→ Best model saved.\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2479 | Acc: 0.5668 | Prec: 0.8096 | Rec: 0.6425 | F1: 0.7164\n",
      " Val  Loss: 0.2547 | Acc: 0.5547 | Prec: 0.7871 | Rec: 0.6576 | F1: 0.7166\n",
      "→ Best model saved.\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2434 | Acc: 0.5688 | Prec: 0.8094 | Rec: 0.6485 | F1: 0.7200\n",
      " Val  Loss: 0.2638 | Acc: 0.5653 | Prec: 0.8102 | Rec: 0.6299 | F1: 0.7088\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2388 | Acc: 0.5671 | Prec: 0.8068 | Rec: 0.6564 | F1: 0.7239\n",
      " Val  Loss: 0.2606 | Acc: 0.5258 | Prec: 0.7524 | Rec: 0.6796 | F1: 0.7141\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2325 | Acc: 0.5683 | Prec: 0.8081 | Rec: 0.6630 | F1: 0.7284\n",
      " Val  Loss: 0.2608 | Acc: 0.5547 | Prec: 0.7872 | Rec: 0.6548 | F1: 0.7150\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2257 | Acc: 0.5695 | Prec: 0.8104 | Rec: 0.6714 | F1: 0.7343\n",
      " Val  Loss: 0.2666 | Acc: 0.5458 | Prec: 0.7813 | Rec: 0.6523 | F1: 0.7110\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2181 | Acc: 0.5765 | Prec: 0.8151 | Rec: 0.6861 | F1: 0.7451\n",
      " Val  Loss: 0.2721 | Acc: 0.5227 | Prec: 0.7742 | Rec: 0.6230 | F1: 0.6904\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2093 | Acc: 0.5792 | Prec: 0.8209 | Rec: 0.6955 | F1: 0.7530\n",
      " Val  Loss: 0.2856 | Acc: 0.5473 | Prec: 0.7919 | Rec: 0.6228 | F1: 0.6972\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1985 | Acc: 0.5938 | Prec: 0.8311 | Rec: 0.7107 | F1: 0.7662\n",
      " Val  Loss: 0.2875 | Acc: 0.5190 | Prec: 0.7435 | Rec: 0.6632 | F1: 0.7011\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1882 | Acc: 0.6086 | Prec: 0.8393 | Rec: 0.7326 | F1: 0.7823\n",
      " Val  Loss: 0.2977 | Acc: 0.5104 | Prec: 0.7414 | Rec: 0.6512 | F1: 0.6934\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1787 | Acc: 0.6226 | Prec: 0.8437 | Rec: 0.7513 | F1: 0.7949\n",
      " Val  Loss: 0.3104 | Acc: 0.4879 | Prec: 0.7196 | Rec: 0.6398 | F1: 0.6774\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1682 | Acc: 0.6397 | Prec: 0.8551 | Rec: 0.7684 | F1: 0.8094\n",
      " Val  Loss: 0.3129 | Acc: 0.4981 | Prec: 0.7365 | Rec: 0.6292 | F1: 0.6787\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1579 | Acc: 0.6615 | Prec: 0.8674 | Rec: 0.7852 | F1: 0.8243\n",
      " Val  Loss: 0.3341 | Acc: 0.4773 | Prec: 0.7066 | Rec: 0.6262 | F1: 0.6640\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1457 | Acc: 0.6831 | Prec: 0.8765 | Rec: 0.8048 | F1: 0.8391\n",
      " Val  Loss: 0.3595 | Acc: 0.4879 | Prec: 0.7129 | Rec: 0.6542 | F1: 0.6823\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1353 | Acc: 0.7014 | Prec: 0.8852 | Rec: 0.8221 | F1: 0.8525\n",
      " Val  Loss: 0.3675 | Acc: 0.4616 | Prec: 0.7011 | Rec: 0.6153 | F1: 0.6554\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1254 | Acc: 0.7239 | Prec: 0.8928 | Rec: 0.8360 | F1: 0.8635\n",
      " Val  Loss: 0.3803 | Acc: 0.4442 | Prec: 0.6802 | Rec: 0.6508 | F1: 0.6651\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1162 | Acc: 0.7402 | Prec: 0.8983 | Rec: 0.8503 | F1: 0.8736\n",
      " Val  Loss: 0.3981 | Acc: 0.4624 | Prec: 0.6924 | Rec: 0.6396 | F1: 0.6650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.2477 | Acc: 0.5599 | Prec: 0.8008 | Rec: 0.6671 | F1: 0.7279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_model(model, train_ld, val_ld, optimizer, criterion, device, epochs, save_path)\n",
    "test_model(model, test_ld, criterion, device, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46ee166",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d409d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkedCrossAttnViT_tuned(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        face_dim: int = 512,\n",
    "        face_chunks: int = 8,\n",
    "        pose_dim: int = 34,\n",
    "        pose_chunks: int = 2,\n",
    "        hidden_dim: int = 256,\n",
    "        num_classes: int = 7,\n",
    "        n_heads: int = 4,\n",
    "        face_layers: int = 2,\n",
    "        pose_layers: int = 2,\n",
    "        fusion_layers: int = 4,\n",
    "        dropout_rate: float = 0.3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert face_dim % face_chunks == 0\n",
    "        assert pose_dim % pose_chunks == 0\n",
    "\n",
    "        self.face_chunks = face_chunks\n",
    "        self.pose_chunks = pose_chunks\n",
    "        self.f_chunk_size = face_dim // face_chunks\n",
    "        self.p_chunk_size = pose_dim // pose_chunks\n",
    "\n",
    "        self.face_proj = nn.Linear(self.f_chunk_size, hidden_dim)\n",
    "        self.pose_proj = nn.Linear(self.p_chunk_size, hidden_dim)\n",
    "\n",
    "        fe = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=n_heads, dropout=dropout_rate, batch_first=True)\n",
    "        self.face_enc = nn.TransformerEncoder(fe, num_layers=face_layers)\n",
    "        pe = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=n_heads, dropout=dropout_rate, batch_first=True)\n",
    "        self.pose_enc = nn.TransformerEncoder(pe, num_layers=pose_layers)\n",
    "\n",
    "        self.f2p_attn = nn.MultiheadAttention(hidden_dim, n_heads, batch_first=True)\n",
    "        self.p2f_attn = nn.MultiheadAttention(hidden_dim, n_heads, batch_first=True)\n",
    "\n",
    "        total_tokens = 1 + face_chunks + pose_chunks\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, hidden_dim))\n",
    "        self.pos_emb = nn.Parameter(torch.randn(1, total_tokens, hidden_dim))\n",
    "\n",
    "        fu = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=n_heads, dropout=dropout_rate, batch_first=True)\n",
    "        self.fusion_enc = nn.TransformerEncoder(fu, num_layers=fusion_layers)\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate),  # <-- Apply dropout here\n",
    "            nn.Linear(hidden_dim // 2, num_classes),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, face: torch.Tensor, pose: torch.Tensor) -> torch.Tensor:\n",
    "        B = face.size(0)\n",
    "\n",
    "        f = face.view(B, self.face_chunks, self.f_chunk_size)\n",
    "        f = self.face_proj(f)\n",
    "        f = self.face_enc(f)\n",
    "\n",
    "        p = pose.view(B, self.pose_chunks, self.p_chunk_size)\n",
    "        p = self.pose_proj(p)\n",
    "        p = self.pose_enc(p)\n",
    "\n",
    "        f2p, _ = self.f2p_attn(query=f, key=p, value=p)\n",
    "        f = f + f2p\n",
    "        p2f, _ = self.p2f_attn(query=p, key=f, value=f)\n",
    "        p = p + p2f\n",
    "\n",
    "        cls = self.cls_token.expand(B, -1, -1)\n",
    "        seq = torch.cat([cls, f, p], dim=1) + self.pos_emb\n",
    "\n",
    "        fused = self.fusion_enc(seq)\n",
    "        cls_out = fused[:, 0]\n",
    "        return self.mlp_head(cls_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27c857d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience: int = 3, min_delta: float = 0.0, verbose: bool = False):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss: float):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6c42223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    device,\n",
    "    epochs: int = 20,\n",
    "    save_path: str = \"best_vit_crossattn_tuned.pt\",\n",
    "    patience: int = 5\n",
    "):\n",
    "    best_val_loss = float('inf')\n",
    "    early_stopper = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "\n",
    "        train_loss, train_metrics = train_one_epoch(\n",
    "            model, train_loader, optimizer, criterion, device\n",
    "        )\n",
    "        val_loss, val_metrics = evaluate(\n",
    "            model, val_loader, criterion, device, mode=\"Validation\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Train Loss: {train_loss:.4f} | \"\n",
    "            f\"Acc: {train_metrics['accuracy']:.4f} | \"\n",
    "            f\"Prec: {train_metrics['precision']:.4f} | \"\n",
    "            f\"Rec: {train_metrics['recall']:.4f} | \"\n",
    "            f\"F1: {train_metrics['f1']:.4f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\" Val  Loss: {val_loss:.4f} | \"\n",
    "            f\"Acc: {val_metrics['accuracy']:.4f} | \"\n",
    "            f\"Prec: {val_metrics['precision']:.4f} | \"\n",
    "            f\"Rec: {val_metrics['recall']:.4f} | \"\n",
    "            f\"F1: {val_metrics['f1']:.4f}\"\n",
    "        )\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"→ Best model saved.\")\n",
    "\n",
    "        early_stopper(val_loss)\n",
    "        if early_stopper.early_stop:\n",
    "            print(\"→ Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbb9b702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2844 | Acc: 0.5583 | Prec: 0.7984 | Rec: 0.6231 | F1: 0.7000\n",
      " Val  Loss: 0.2665 | Acc: 0.5624 | Prec: 0.8129 | Rec: 0.6148 | F1: 0.7001\n",
      "→ Best model saved.\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2671 | Acc: 0.5616 | Prec: 0.8075 | Rec: 0.6258 | F1: 0.7052\n",
      " Val  Loss: 0.2631 | Acc: 0.5641 | Prec: 0.7980 | Rec: 0.6439 | F1: 0.7127\n",
      "→ Best model saved.\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2631 | Acc: 0.5598 | Prec: 0.8087 | Rec: 0.6278 | F1: 0.7068\n",
      " Val  Loss: 0.2612 | Acc: 0.5498 | Prec: 0.7847 | Rec: 0.6553 | F1: 0.7142\n",
      "→ Best model saved.\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2595 | Acc: 0.5636 | Prec: 0.8082 | Rec: 0.6340 | F1: 0.7106\n",
      " Val  Loss: 0.2571 | Acc: 0.5627 | Prec: 0.8023 | Rec: 0.6381 | F1: 0.7108\n",
      "→ Best model saved.\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2586 | Acc: 0.5637 | Prec: 0.8092 | Rec: 0.6333 | F1: 0.7105\n",
      " Val  Loss: 0.2571 | Acc: 0.5636 | Prec: 0.8186 | Rec: 0.6161 | F1: 0.7031\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2558 | Acc: 0.5618 | Prec: 0.8085 | Rec: 0.6318 | F1: 0.7093\n",
      " Val  Loss: 0.2568 | Acc: 0.5621 | Prec: 0.8019 | Rec: 0.6415 | F1: 0.7128\n",
      "→ Best model saved.\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2527 | Acc: 0.5646 | Prec: 0.8087 | Rec: 0.6360 | F1: 0.7120\n",
      " Val  Loss: 0.2599 | Acc: 0.5387 | Prec: 0.7724 | Rec: 0.6649 | F1: 0.7147\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2521 | Acc: 0.5626 | Prec: 0.8081 | Rec: 0.6358 | F1: 0.7117\n",
      " Val  Loss: 0.2596 | Acc: 0.5493 | Prec: 0.7807 | Rec: 0.6570 | F1: 0.7135\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2496 | Acc: 0.5631 | Prec: 0.8091 | Rec: 0.6365 | F1: 0.7125\n",
      " Val  Loss: 0.2604 | Acc: 0.5461 | Prec: 0.7767 | Rec: 0.6598 | F1: 0.7135\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2477 | Acc: 0.5625 | Prec: 0.8075 | Rec: 0.6399 | F1: 0.7140\n",
      " Val  Loss: 0.2589 | Acc: 0.5593 | Prec: 0.7976 | Rec: 0.6458 | F1: 0.7137\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2454 | Acc: 0.5615 | Prec: 0.8072 | Rec: 0.6416 | F1: 0.7150\n",
      " Val  Loss: 0.2614 | Acc: 0.5416 | Prec: 0.7659 | Rec: 0.6675 | F1: 0.7133\n",
      "EarlyStopping counter: 5 out of 5\n",
      "→ Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.2483 | Acc: 0.5630 | Prec: 0.8124 | Rec: 0.6480 | F1: 0.7210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model = ChunkedCrossAttnViT_tuned(dropout_rate=0.3).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "train_model(model, train_ld, val_ld, optimizer, criterion, device, epochs=20, save_path=\"best_vit_crossattn_tuned.pt\", patience=5)\n",
    "test_model(model, test_ld, criterion, device, save_path=\"best_vit_crossattn_tuned.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f9b1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
