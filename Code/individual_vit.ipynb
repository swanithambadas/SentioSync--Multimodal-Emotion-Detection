{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c79a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "353e14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path    = \"final_annotations.json\"\n",
    "batch_size   = 32\n",
    "epochs       = 20\n",
    "lr           = 1e-4\n",
    "weight_decay = 1e-2\n",
    "device       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a0e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, json_path, split='train'):\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        self.samples = []\n",
    "        for item in data[split]:\n",
    "            face = item.get('face_embedding')\n",
    "            pose = item.get('pose_embedding')\n",
    "            label = item.get('multi_hot')\n",
    "            if face is None or pose is None or label is None:\n",
    "                continue\n",
    "            if any(x is None for x in face) or any(x is None for x in pose) or any(x is None for x in label):\n",
    "                continue\n",
    "            self.samples.append((face, pose, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        face, pose, label = self.samples[idx]\n",
    "        return (\n",
    "            torch.tensor(face, dtype=torch.float32),\n",
    "            torch.tensor(pose, dtype=torch.float32),\n",
    "            torch.tensor(label, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4008e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceViT(nn.Module):\n",
    "    def __init__(self, face_dim=512, hidden_dim=256, num_classes=7, n_heads=4, n_layers=4):\n",
    "        super().__init__()\n",
    "        self.face_proj = nn.Linear(face_dim, hidden_dim)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, hidden_dim))\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 2, hidden_dim))  # [CLS] + face\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=n_heads, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, face, pose):\n",
    "        face_tok = self.face_proj(face).unsqueeze(1)\n",
    "        cls_tok  = self.cls_token.expand(face.size(0), -1, -1)\n",
    "        x = torch.cat([cls_tok, face_tok], dim=1) + self.pos_embedding\n",
    "        x = self.transformer(x)\n",
    "        return self.mlp_head(x[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c24d59e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseViT(nn.Module):\n",
    "    def __init__(self, pose_dim=34, hidden_dim=256, num_classes=7, n_heads=4, n_layers=4):\n",
    "        super().__init__()\n",
    "        self.pose_proj = nn.Linear(pose_dim, hidden_dim)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, hidden_dim))\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, 2, hidden_dim))  # [CLS] + pose\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=n_heads, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, face, pose):\n",
    "        # ignore `face`\n",
    "        pose_tok = self.pose_proj(pose).unsqueeze(1)\n",
    "        cls_tok  = self.cls_token.expand(pose.size(0), -1, -1)\n",
    "        x = torch.cat([cls_tok, pose_tok], dim=1) + self.pos_embedding\n",
    "        x = self.transformer(x)\n",
    "        return self.mlp_head(x[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e80fa9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, threshold=0.5):\n",
    "    y_pred_bin = (y_pred > threshold).astype(int)\n",
    "    return {\n",
    "        \"accuracy\":  accuracy_score(y_true, y_pred_bin),\n",
    "        \"precision\": precision_score(y_true, y_pred_bin, average='micro', zero_division=0),\n",
    "        \"recall\":    recall_score(y_true, y_pred_bin, average='micro', zero_division=0),\n",
    "        \"f1\":        f1_score(y_true, y_pred_bin, average='micro', zero_division=0)\n",
    "    }\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss, all_labels, all_preds = 0.0, [], []\n",
    "    for face, pose, label in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        face, pose, label = face.to(device), pose.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(face, pose)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        all_labels.append(label.cpu().numpy())\n",
    "        all_preds.append(output.detach().cpu().numpy())\n",
    "    y_true = np.vstack(all_labels)\n",
    "    y_pred = np.vstack(all_preds)\n",
    "    return total_loss / len(loader), compute_metrics(y_true, y_pred)\n",
    "\n",
    "def evaluate(model, loader, criterion, device, mode=\"Validation\"):\n",
    "    model.eval()\n",
    "    total_loss, all_labels, all_preds = 0.0, [], []\n",
    "    with torch.no_grad():\n",
    "        for face, pose, label in tqdm(loader, desc=mode, leave=False):\n",
    "            face, pose, label = face.to(device), pose.to(device), label.to(device)\n",
    "            output = model(face, pose)\n",
    "            loss = criterion(output, label)\n",
    "            total_loss += loss.item()\n",
    "            all_labels.append(label.cpu().numpy())\n",
    "            all_preds.append(output.cpu().numpy())\n",
    "    y_true = np.vstack(all_labels)\n",
    "    y_pred = np.vstack(all_preds)\n",
    "    return total_loss / len(loader), compute_metrics(y_true, y_pred)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs, save_path):\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        tr_loss, tr_metrics = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_metrics = evaluate(model, val_loader, criterion, device)\n",
    "        print(f\"Train Loss: {tr_loss:.4f} | Acc: {tr_metrics['accuracy']:.4f} | \"\n",
    "              f\"Prec: {tr_metrics['precision']:.4f} | Rec: {tr_metrics['recall']:.4f} | F1: {tr_metrics['f1']:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f} | Acc: {val_metrics['accuracy']:.4f} | \"\n",
    "              f\"Prec: {val_metrics['precision']:.4f} | Rec: {val_metrics['recall']:.4f} | F1: {val_metrics['f1']:.4f}\")\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"→ Best model saved.\")\n",
    "\n",
    "def test_model(model, test_loader, criterion, device, save_path):\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    test_loss, test_metrics = evaluate(model, test_loader, criterion, device, mode=\"Test\")\n",
    "    print(f\"\\nTest Loss: {test_loss:.4f} | Acc: {test_metrics['accuracy']:.4f} | \"\n",
    "          f\"Prec: {test_metrics['precision']:.4f} | Rec: {test_metrics['recall']:.4f} | F1: {test_metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cad13328",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmotionDataset(json_path, split=\"train\")\n",
    "val_dataset   = EmotionDataset(json_path, split=\"val\")\n",
    "test_dataset  = EmotionDataset(json_path, split=\"test\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "648172f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2695 | Acc: 0.5670 | Prec: 0.8080 | Rec: 0.6234 | F1: 0.7038\n",
      "Val   Loss: 0.2628 | Acc: 0.5616 | Prec: 0.7965 | Rec: 0.6441 | F1: 0.7122\n",
      "→ Best model saved.\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2570 | Acc: 0.5637 | Prec: 0.8081 | Rec: 0.6321 | F1: 0.7093\n",
      "Val   Loss: 0.2532 | Acc: 0.5644 | Prec: 0.8067 | Rec: 0.6346 | F1: 0.7104\n",
      "→ Best model saved.\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2538 | Acc: 0.5650 | Prec: 0.8088 | Rec: 0.6328 | F1: 0.7101\n",
      "Val   Loss: 0.2556 | Acc: 0.5667 | Prec: 0.8091 | Rec: 0.6391 | F1: 0.7142\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2512 | Acc: 0.5638 | Prec: 0.8066 | Rec: 0.6361 | F1: 0.7113\n",
      "Val   Loss: 0.2527 | Acc: 0.5693 | Prec: 0.8200 | Rec: 0.6241 | F1: 0.7088\n",
      "→ Best model saved.\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2495 | Acc: 0.5679 | Prec: 0.8085 | Rec: 0.6399 | F1: 0.7144\n",
      "Val   Loss: 0.2547 | Acc: 0.5687 | Prec: 0.8154 | Rec: 0.6280 | F1: 0.7095\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2484 | Acc: 0.5665 | Prec: 0.8081 | Rec: 0.6412 | F1: 0.7150\n",
      "Val   Loss: 0.2537 | Acc: 0.5513 | Prec: 0.7828 | Rec: 0.6667 | F1: 0.7201\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2468 | Acc: 0.5631 | Prec: 0.8047 | Rec: 0.6429 | F1: 0.7148\n",
      "Val   Loss: 0.2520 | Acc: 0.5641 | Prec: 0.8111 | Rec: 0.6297 | F1: 0.7090\n",
      "→ Best model saved.\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2458 | Acc: 0.5678 | Prec: 0.8082 | Rec: 0.6442 | F1: 0.7169\n",
      "Val   Loss: 0.2523 | Acc: 0.5564 | Prec: 0.7859 | Rec: 0.6624 | F1: 0.7189\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2444 | Acc: 0.5663 | Prec: 0.8056 | Rec: 0.6465 | F1: 0.7173\n",
      "Val   Loss: 0.2542 | Acc: 0.5644 | Prec: 0.8202 | Rec: 0.6200 | F1: 0.7062\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2433 | Acc: 0.5662 | Prec: 0.8065 | Rec: 0.6486 | F1: 0.7190\n",
      "Val   Loss: 0.2520 | Acc: 0.5656 | Prec: 0.8254 | Rec: 0.6202 | F1: 0.7083\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2419 | Acc: 0.5682 | Prec: 0.8068 | Rec: 0.6510 | F1: 0.7206\n",
      "Val   Loss: 0.2593 | Acc: 0.5510 | Prec: 0.8012 | Rec: 0.6155 | F1: 0.6962\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2409 | Acc: 0.5676 | Prec: 0.8056 | Rec: 0.6527 | F1: 0.7211\n",
      "Val   Loss: 0.2531 | Acc: 0.5653 | Prec: 0.8249 | Rec: 0.6189 | F1: 0.7072\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2392 | Acc: 0.5672 | Prec: 0.8060 | Rec: 0.6535 | F1: 0.7218\n",
      "Val   Loss: 0.2564 | Acc: 0.5544 | Prec: 0.7949 | Rec: 0.6417 | F1: 0.7101\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2370 | Acc: 0.5687 | Prec: 0.8076 | Rec: 0.6563 | F1: 0.7241\n",
      "Val   Loss: 0.2595 | Acc: 0.5564 | Prec: 0.7923 | Rec: 0.6505 | F1: 0.7145\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2349 | Acc: 0.5704 | Prec: 0.8068 | Rec: 0.6609 | F1: 0.7266\n",
      "Val   Loss: 0.2590 | Acc: 0.5578 | Prec: 0.7912 | Rec: 0.6460 | F1: 0.7113\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2326 | Acc: 0.5686 | Prec: 0.8073 | Rec: 0.6635 | F1: 0.7284\n",
      "Val   Loss: 0.2610 | Acc: 0.5538 | Prec: 0.7858 | Rec: 0.6540 | F1: 0.7138\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2292 | Acc: 0.5677 | Prec: 0.8045 | Rec: 0.6706 | F1: 0.7315\n",
      "Val   Loss: 0.2611 | Acc: 0.5581 | Prec: 0.7956 | Rec: 0.6372 | F1: 0.7077\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2256 | Acc: 0.5725 | Prec: 0.8082 | Rec: 0.6742 | F1: 0.7351\n",
      "Val   Loss: 0.2674 | Acc: 0.5556 | Prec: 0.8028 | Rec: 0.6241 | F1: 0.7022\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2217 | Acc: 0.5727 | Prec: 0.8073 | Rec: 0.6812 | F1: 0.7389\n",
      "Val   Loss: 0.2694 | Acc: 0.5338 | Prec: 0.7667 | Rec: 0.6630 | F1: 0.7111\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2157 | Acc: 0.5745 | Prec: 0.8097 | Rec: 0.6918 | F1: 0.7461\n",
      "Val   Loss: 0.2707 | Acc: 0.5470 | Prec: 0.7858 | Rec: 0.6452 | F1: 0.7085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.2470 | Acc: 0.5584 | Prec: 0.8134 | Rec: 0.6375 | F1: 0.7148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "model_face = FaceViT().to(device)\n",
    "optimizer   = optim.AdamW(model_face.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion   = nn.BCELoss()\n",
    "save_path_f = \"best_face_vit.pt\"\n",
    "\n",
    "train_model(model_face, train_loader, val_loader, optimizer, criterion, device, epochs, save_path_f)\n",
    "test_model(model_face, test_loader, criterion, device, save_path_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad70d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2733 | Acc: 0.5672 | Prec: 0.8116 | Rec: 0.6166 | F1: 0.7008\n",
      "Val   Loss: 0.2677 | Acc: 0.5638 | Prec: 0.8149 | Rec: 0.6135 | F1: 0.7000\n",
      "→ Best model saved.\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  56%|█████▋    | 294/521 [00:02<00:01, 126.15it/s]"
     ]
    }
   ],
   "source": [
    "model_pose = PoseViT().to(device)\n",
    "optimizer   = optim.AdamW(model_pose.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion   = nn.BCELoss()\n",
    "save_path_p = \"best_pose_vit.pt\"\n",
    "\n",
    "train_model(model_pose, train_loader, val_loader, optimizer, criterion, device, epochs, save_path_p)\n",
    "test_model(model_pose, test_loader, criterion, device, save_path_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c6bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
