{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c32ab2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9930040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, json_path, split='train'):\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        self.samples = []\n",
    "        for item in data[split]:\n",
    "            face = item.get('face_embedding')\n",
    "            pose = item.get('pose_embedding')\n",
    "            label = item.get('multi_hot')\n",
    "\n",
    "            if face is None or pose is None or label is None:\n",
    "                continue\n",
    "            if any(x is None for x in face) or any(x is None for x in pose) or any(x is None for x in label):\n",
    "                continue\n",
    "\n",
    "            self.samples.append((face, pose, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        face, pose, label = self.samples[idx]\n",
    "        return (\n",
    "            torch.tensor(face, dtype=torch.float32),\n",
    "            torch.tensor(pose, dtype=torch.float32),\n",
    "            torch.tensor(label, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3c1b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkedViT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        face_dim=512,\n",
    "        face_chunks=8,\n",
    "        pose_dim=34,\n",
    "        pose_chunks=2,\n",
    "        hidden_dim=256,\n",
    "        num_classes=7,\n",
    "        n_heads=4,\n",
    "        n_layers=4\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert face_dim % face_chunks == 0\n",
    "        assert pose_dim % pose_chunks == 0\n",
    "\n",
    "        self.f_chunk_size = face_dim // face_chunks\n",
    "        self.p_chunk_size = pose_dim // pose_chunks\n",
    "        self.face_chunks = face_chunks\n",
    "        self.pose_chunks = pose_chunks\n",
    "\n",
    "        self.face_proj = nn.Linear(self.f_chunk_size, hidden_dim)\n",
    "        self.pose_proj = nn.Linear(self.p_chunk_size, hidden_dim)\n",
    "\n",
    "        total_tokens = 1 + face_chunks + pose_chunks\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, hidden_dim))\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, total_tokens, hidden_dim))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=n_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, face, pose):\n",
    "        B = face.size(0)\n",
    "\n",
    "        face_tokens = face.view(B, self.face_chunks, self.f_chunk_size)\n",
    "        face_tokens = self.face_proj(face_tokens)\n",
    "\n",
    "        pose_tokens = pose.view(B, self.pose_chunks, self.p_chunk_size)\n",
    "        pose_tokens = self.pose_proj(pose_tokens)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "\n",
    "        x = torch.cat([cls_tokens, face_tokens, pose_tokens], dim=1)\n",
    "        x = x + self.pos_embedding\n",
    "\n",
    "        x = self.transformer(x)\n",
    "        cls_out = x[:, 0]\n",
    "        return self.mlp_head(cls_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec03f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, threshold=0.5):\n",
    "    y_pred_bin = (y_pred > threshold).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred_bin)\n",
    "    precision = precision_score(y_true, y_pred_bin, average='micro', zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred_bin, average='micro', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred_bin, average='micro', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_labels, all_preds = [], []\n",
    "\n",
    "    for face, pose, label in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "        face, pose, label = face.to(device), pose.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(face, pose)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_labels.append(label.cpu().numpy())\n",
    "        all_preds.append(output.detach().cpu().numpy())\n",
    "\n",
    "    y_true = np.vstack(all_labels)\n",
    "    y_pred = np.vstack(all_preds)\n",
    "    metrics = compute_metrics(y_true, y_pred)\n",
    "    return total_loss / len(dataloader), metrics\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device, mode=\"Validation\"):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_labels, all_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for face, pose, label in tqdm(dataloader, desc=mode, leave=False):\n",
    "            face, pose, label = face.to(device), pose.to(device), label.to(device)\n",
    "            output = model(face, pose)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            all_labels.append(label.cpu().numpy())\n",
    "            all_preds.append(output.cpu().numpy())\n",
    "\n",
    "    y_true = np.vstack(all_labels)\n",
    "    y_pred = np.vstack(all_preds)\n",
    "    metrics = compute_metrics(y_true, y_pred)\n",
    "    return total_loss / len(dataloader), metrics\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=20, save_path=\"best_vit.pt\"):\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        train_loss, train_metrics = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_metrics = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Acc: {train_metrics['accuracy']:.4f} | Prec: {train_metrics['precision']:.4f} | Rec: {train_metrics['recall']:.4f} | F1: {train_metrics['f1']:.4f}\")\n",
    "        print(f\"Val   Loss: {val_loss:.4f} | Acc: {val_metrics['accuracy']:.4f} | Prec: {val_metrics['precision']:.4f} | Rec: {val_metrics['recall']:.4f} | F1: {val_metrics['f1']:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"Best model saved.\")\n",
    "\n",
    "def test_model(model, test_loader, criterion, device, save_path=\"best_vit.pt\"):\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    test_loss, test_metrics = evaluate(model, test_loader, criterion, device, mode=\"Test\")\n",
    "    print(f\"\\nTest Loss: {test_loss:.4f} | Acc: {test_metrics['accuracy']:.4f} | Prec: {test_metrics['precision']:.4f} | Rec: {test_metrics['recall']:.4f} | F1: {test_metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "354492f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2741 | Acc: 0.5670 | Prec: 0.8105 | Rec: 0.6168 | F1: 0.7005\n",
      "Val   Loss: 0.2691 | Acc: 0.5638 | Prec: 0.8147 | Rec: 0.6138 | F1: 0.7001\n",
      "Best model saved.\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2698 | Acc: 0.5682 | Prec: 0.8153 | Rec: 0.6171 | F1: 0.7025\n",
      "Val   Loss: 0.2697 | Acc: 0.5638 | Prec: 0.8149 | Rec: 0.6135 | F1: 0.7000\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2686 | Acc: 0.5668 | Prec: 0.8136 | Rec: 0.6181 | F1: 0.7025\n",
      "Val   Loss: 0.2683 | Acc: 0.5638 | Prec: 0.8149 | Rec: 0.6135 | F1: 0.7000\n",
      "Best model saved.\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2685 | Acc: 0.5679 | Prec: 0.8148 | Rec: 0.6174 | F1: 0.7025\n",
      "Val   Loss: 0.2706 | Acc: 0.5638 | Prec: 0.8149 | Rec: 0.6135 | F1: 0.7000\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2678 | Acc: 0.5673 | Prec: 0.8142 | Rec: 0.6178 | F1: 0.7025\n",
      "Val   Loss: 0.2708 | Acc: 0.5638 | Prec: 0.8149 | Rec: 0.6135 | F1: 0.7000\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2634 | Acc: 0.5647 | Prec: 0.8119 | Rec: 0.6217 | F1: 0.7042\n",
      "Val   Loss: 0.2609 | Acc: 0.5707 | Prec: 0.8103 | Rec: 0.6340 | F1: 0.7114\n",
      "Best model saved.\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2604 | Acc: 0.5646 | Prec: 0.8087 | Rec: 0.6300 | F1: 0.7082\n",
      "Val   Loss: 0.2583 | Acc: 0.5616 | Prec: 0.8034 | Rec: 0.6389 | F1: 0.7118\n",
      "Best model saved.\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2591 | Acc: 0.5652 | Prec: 0.8116 | Rec: 0.6303 | F1: 0.7096\n",
      "Val   Loss: 0.2567 | Acc: 0.5633 | Prec: 0.8229 | Rec: 0.6127 | F1: 0.7024\n",
      "Best model saved.\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2581 | Acc: 0.5647 | Prec: 0.8109 | Rec: 0.6285 | F1: 0.7082\n",
      "Val   Loss: 0.2571 | Acc: 0.5490 | Prec: 0.7821 | Rec: 0.6576 | F1: 0.7145\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2575 | Acc: 0.5629 | Prec: 0.8086 | Rec: 0.6304 | F1: 0.7085\n",
      "Val   Loss: 0.2573 | Acc: 0.5638 | Prec: 0.8219 | Rec: 0.6144 | F1: 0.7032\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2558 | Acc: 0.5641 | Prec: 0.8089 | Rec: 0.6329 | F1: 0.7102\n",
      "Val   Loss: 0.2562 | Acc: 0.5618 | Prec: 0.8262 | Rec: 0.6095 | F1: 0.7015\n",
      "Best model saved.\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2545 | Acc: 0.5668 | Prec: 0.8105 | Rec: 0.6337 | F1: 0.7113\n",
      "Val   Loss: 0.2545 | Acc: 0.5670 | Prec: 0.8194 | Rec: 0.6237 | F1: 0.7083\n",
      "Best model saved.\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2539 | Acc: 0.5667 | Prec: 0.8073 | Rec: 0.6393 | F1: 0.7135\n",
      "Val   Loss: 0.2532 | Acc: 0.5681 | Prec: 0.8208 | Rec: 0.6206 | F1: 0.7068\n",
      "Best model saved.\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2530 | Acc: 0.5664 | Prec: 0.8095 | Rec: 0.6357 | F1: 0.7122\n",
      "Val   Loss: 0.2551 | Acc: 0.5684 | Prec: 0.8037 | Rec: 0.6437 | F1: 0.7148\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2526 | Acc: 0.5667 | Prec: 0.8059 | Rec: 0.6403 | F1: 0.7136\n",
      "Val   Loss: 0.2520 | Acc: 0.5733 | Prec: 0.8143 | Rec: 0.6404 | F1: 0.7170\n",
      "Best model saved.\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2513 | Acc: 0.5691 | Prec: 0.8091 | Rec: 0.6416 | F1: 0.7157\n",
      "Val   Loss: 0.2553 | Acc: 0.5547 | Prec: 0.7870 | Rec: 0.6581 | F1: 0.7168\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2503 | Acc: 0.5672 | Prec: 0.8068 | Rec: 0.6432 | F1: 0.7157\n",
      "Val   Loss: 0.2521 | Acc: 0.5707 | Prec: 0.8095 | Rec: 0.6434 | F1: 0.7170\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2488 | Acc: 0.5680 | Prec: 0.8079 | Rec: 0.6439 | F1: 0.7166\n",
      "Val   Loss: 0.2532 | Acc: 0.5738 | Prec: 0.8098 | Rec: 0.6402 | F1: 0.7151\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2520 | Acc: 0.5670 | Prec: 0.8079 | Rec: 0.6380 | F1: 0.7130\n",
      "Val   Loss: 0.2549 | Acc: 0.5621 | Prec: 0.8234 | Rec: 0.6155 | F1: 0.7044\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2478 | Acc: 0.5673 | Prec: 0.8091 | Rec: 0.6417 | F1: 0.7157\n",
      "Val   Loss: 0.2560 | Acc: 0.5667 | Prec: 0.8051 | Rec: 0.6512 | F1: 0.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.2474 | Acc: 0.5663 | Prec: 0.8198 | Rec: 0.6430 | F1: 0.7207\n"
     ]
    }
   ],
   "source": [
    "json_path = \"final_annotations.json\"\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "save_path = \"best_chunked_vit.pt\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "train_dataset = EmotionDataset(json_path, split=\"train\")\n",
    "val_dataset = EmotionDataset(json_path, split=\"val\")\n",
    "test_dataset = EmotionDataset(json_path, split=\"test\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "model = ChunkedViT().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=epochs, save_path=save_path)\n",
    "test_model(model, test_loader, criterion, device, save_path=save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
