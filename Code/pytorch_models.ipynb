{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a80396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, inception_v3, googlenet\n",
    "from PIL import Image\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99a146cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path    = \"final_annotations.json\"\n",
    "batch_size   = 32\n",
    "epochs       = 10\n",
    "lr           = 1e-4\n",
    "weight_decay = 1e-2\n",
    "device       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes  = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdbf9c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionImageDataset(Dataset):\n",
    "    def __init__(self, json_path, split='train', img_size=224):\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        self.samples = data[split]\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485,0.456,0.406],\n",
    "                                 [0.229,0.224,0.225]),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.samples[idx]\n",
    "        img = Image.open(item['image_path']).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        face = torch.tensor(item['face_embedding'], dtype=torch.float32)\n",
    "        pose = torch.tensor(item['pose_embedding'], dtype=torch.float32)\n",
    "        label = torch.tensor(item['multi_hot'], dtype=torch.float32)\n",
    "        return img, face, pose, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ce394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backbone(name):\n",
    "    if name == 'resnet50':\n",
    "        model = resnet50(pretrained=True)\n",
    "        feat_dim = model.fc.in_features\n",
    "        model.fc = nn.Identity()\n",
    "        return model, feat_dim\n",
    "\n",
    "    if name == 'inception_v3':\n",
    "        model = inception_v3(pretrained=True)  \n",
    "        feat_dim = model.fc.in_features\n",
    "        model.fc = nn.Identity()\n",
    "        model.aux_logits = False\n",
    "        model.AuxLogits = nn.Identity()\n",
    "        return model, feat_dim\n",
    "    \n",
    "    if name == 'googlenet':\n",
    "        weights = GoogLeNet_Weights.IMAGENET1K_V1\n",
    "        model = googlenet(weights=weights, aux_logits=True)\n",
    "        model.aux_logits = False\n",
    "        feat_dim = model.fc.in_features\n",
    "        model.fc = nn.Identity()\n",
    "        return model, feat_dim\n",
    "\n",
    "    raise ValueError(f\"Unknown backbone: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f995598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalNet(nn.Module):\n",
    "    def __init__(self, backbone_name, face_dim=512, pose_dim=34, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.backbone, img_feat = get_backbone(backbone_name)\n",
    "        self.face_proj = nn.Linear(face_dim, hidden_dim)\n",
    "        self.pose_proj = nn.Linear(pose_dim, hidden_dim)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(img_feat + hidden_dim*2, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img, face, pose):\n",
    "        img_feat = self.backbone(img)           \n",
    "        f = self.face_proj(face)               \n",
    "        p = self.pose_proj(pose)                \n",
    "        x = torch.cat([img_feat, f, p], dim=1) \n",
    "        return self.classifier(x)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d096c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, thr=0.5):\n",
    "    y_pred_bin = (y_pred > thr).astype(int)\n",
    "    return {\n",
    "        'accuracy':  accuracy_score(y_true, y_pred_bin),\n",
    "        'precision': precision_score(y_true, y_pred_bin, average='micro', zero_division=0),\n",
    "        'recall':    recall_score(y_true, y_pred_bin, average='micro', zero_division=0),\n",
    "        'f1':        f1_score(y_true, y_pred_bin, average='micro', zero_division=0)\n",
    "    }\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    losses, Ys, Ps = [], [], []\n",
    "    for img, face, pose, label in tqdm(dataloader, desc=\"Train\", leave=False):\n",
    "        img, face, pose, label = img.to(device), face.to(device), pose.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(img, face, pose)\n",
    "        loss = criterion(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        Ys.append(label.detach().cpu().numpy())\n",
    "        Ps.append(out.detach().cpu().numpy())\n",
    "    y_true = np.vstack(Ys)\n",
    "    y_pred = np.vstack(Ps)\n",
    "    return np.mean(losses), compute_metrics(y_true, y_pred)\n",
    "\n",
    "def eval_epoch(model, dataloader, criterion, desc=\"Val\"):\n",
    "    model.eval()\n",
    "    losses, Ys, Ps = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for img, face, pose, label in tqdm(dataloader, desc=desc, leave=False):\n",
    "            img, face, pose, label = img.to(device), face.to(device), pose.to(device), label.to(device)\n",
    "            out = model(img, face, pose)\n",
    "            losses.append(criterion(out, label).item())\n",
    "            Ys.append(label.cpu().numpy())\n",
    "            Ps.append(out.cpu().numpy())\n",
    "    y_true = np.vstack(Ys)\n",
    "    y_pred = np.vstack(Ps)\n",
    "    return np.mean(losses), compute_metrics(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b26c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = EmotionImageDataset(json_path, split='train', img_size=224)\n",
    "val_ds   = EmotionImageDataset(json_path, split='val',   img_size=224)\n",
    "test_ds  = EmotionImageDataset(json_path, split='test',  img_size=224)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47043f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Backbone: RESNET50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/torchvision/0.14.1-CUDA-11.8.0/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/torchvision/0.14.1-CUDA-11.8.0/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.4470, acc: 0.4613, prec: 0.7048, rec: 0.6197, f1: 0.6595\n",
      "  Val   → loss: 0.2761, acc: 0.5633, prec: 0.8127, rec: 0.6142, f1: 0.6997\n",
      "Saved best model.\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.2875, acc: 0.5409, prec: 0.7812, rec: 0.6319, f1: 0.6987\n",
      "  Val   → loss: 0.2658, acc: 0.5656, prec: 0.8137, rec: 0.6170, f1: 0.7018\n",
      "Saved best model.\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.2740, acc: 0.5571, prec: 0.7943, rec: 0.6361, f1: 0.7064\n",
      "  Val   → loss: 0.2666, acc: 0.5647, prec: 0.8021, rec: 0.6335, f1: 0.7079\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.2570, acc: 0.5634, prec: 0.7952, rec: 0.6448, f1: 0.7121\n",
      "  Val   → loss: 0.2706, acc: 0.5627, prec: 0.8011, rec: 0.6340, f1: 0.7078\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.2400, acc: 0.5705, prec: 0.7998, rec: 0.6520, f1: 0.7184\n",
      "  Val   → loss: 0.2818, acc: 0.5576, prec: 0.7941, rec: 0.6361, f1: 0.7064\n",
      "Epoch 00005: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.2094, acc: 0.5838, prec: 0.8035, rec: 0.6777, f1: 0.7353\n",
      "  Val   → loss: 0.3036, acc: 0.5450, prec: 0.7760, rec: 0.6518, f1: 0.7085\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.1893, acc: 0.6060, prec: 0.8185, rec: 0.7116, f1: 0.7613\n",
      "  Val   → loss: 0.3111, acc: 0.5356, prec: 0.7722, rec: 0.6488, f1: 0.7052\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.1735, acc: 0.6378, prec: 0.8328, rec: 0.7426, f1: 0.7851\n",
      "  Val   → loss: 0.3383, acc: 0.5156, prec: 0.7491, rec: 0.6613, f1: 0.7025\n",
      "Epoch 00008: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.1552, acc: 0.6654, prec: 0.8437, rec: 0.7662, f1: 0.8031\n",
      "  Val   → loss: 0.3725, acc: 0.5010, prec: 0.7384, rec: 0.6557, f1: 0.6946\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.1441, acc: 0.6858, prec: 0.8536, rec: 0.7864, f1: 0.8186\n",
      "  Val   → loss: 0.3814, acc: 0.4844, prec: 0.7215, rec: 0.6570, f1: 0.6878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/torchvision/0.14.1-CUDA-11.8.0/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/torchvision/0.14.1-CUDA-11.8.0/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Test → loss: 0.2625, acc: 0.5672, prec: 0.8260, rec: 0.6237, f1: 0.7107\n",
      "\n",
      " Backbone: INCEPTION_V3\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.4555, acc: 0.4726, prec: 0.7101, rec: 0.6190, f1: 0.6614\n",
      "  Val   → loss: 0.2726, acc: 0.5636, prec: 0.8130, rec: 0.6144, f1: 0.6999\n",
      "Saved best model.\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.2805, acc: 0.5526, prec: 0.7910, rec: 0.6305, f1: 0.7017\n",
      "  Val   → loss: 0.2709, acc: 0.5607, prec: 0.8040, rec: 0.6237, f1: 0.7024\n",
      "Saved best model.\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.2629, acc: 0.5637, prec: 0.7987, rec: 0.6336, f1: 0.7067\n",
      "  Val   → loss: 0.2840, acc: 0.5650, prec: 0.8027, rec: 0.6335, f1: 0.7082\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.2449, acc: 0.5653, prec: 0.7980, rec: 0.6406, f1: 0.7107\n",
      "  Val   → loss: 0.2805, acc: 0.5616, prec: 0.8008, rec: 0.6327, f1: 0.7069\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.2290, acc: 0.5772, prec: 0.8009, rec: 0.6510, f1: 0.7182\n",
      "  Val   → loss: 0.2858, acc: 0.5530, prec: 0.7836, rec: 0.6477, f1: 0.7092\n",
      "Epoch 00005: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.2064, acc: 0.5938, prec: 0.8053, rec: 0.6658, f1: 0.7290\n",
      "  Val   → loss: 0.3076, acc: 0.5584, prec: 0.7894, rec: 0.6441, f1: 0.7094\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.1915, acc: 0.6103, prec: 0.8100, rec: 0.6827, f1: 0.7409\n",
      "  Val   → loss: 0.3279, acc: 0.5301, prec: 0.7512, rec: 0.6714, f1: 0.7091\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.1807, acc: 0.6270, prec: 0.8136, rec: 0.7013, f1: 0.7533\n",
      "  Val   → loss: 0.3429, acc: 0.5147, prec: 0.7442, rec: 0.6682, f1: 0.7041\n",
      "Epoch 00008: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.1662, acc: 0.6388, prec: 0.8180, rec: 0.7234, f1: 0.7678\n",
      "  Val   → loss: 0.3554, acc: 0.5298, prec: 0.7607, rec: 0.6514, f1: 0.7018\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.1571, acc: 0.6523, prec: 0.8192, rec: 0.7518, f1: 0.7840\n",
      "  Val   → loss: 0.3842, acc: 0.5013, prec: 0.7281, rec: 0.6761, f1: 0.7012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.ccr.buffalo.edu/versions/2023.01/easybuild/software/avx512/MPI/gcc/11.2.0/openmpi/4.1.1/torchvision/0.14.1-CUDA-11.8.0/lib/python3.9/site-packages/torchvision/models/googlenet.py:339: UserWarning: auxiliary heads in the pretrained googlenet model are NOT pretrained, so make sure to train them\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Test → loss: 0.2652, acc: 0.5680, prec: 0.8159, rec: 0.6339, f1: 0.7134\n",
      "\n",
      " Backbone: GOOGLENET\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.6413, acc: 0.4407, prec: 0.6784, rec: 0.6074, f1: 0.6409\n",
      "  Val   → loss: 0.2766, acc: 0.5630, prec: 0.8144, rec: 0.6133, f1: 0.6997\n",
      "Saved best model.\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.2863, acc: 0.5479, prec: 0.7881, rec: 0.6271, f1: 0.6984\n",
      "  Val   → loss: 0.2658, acc: 0.5636, prec: 0.8120, rec: 0.6168, f1: 0.7011\n",
      "Saved best model.\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.2598, acc: 0.5608, prec: 0.7980, rec: 0.6318, f1: 0.7053\n",
      "  Val   → loss: 0.2723, acc: 0.5627, prec: 0.8091, rec: 0.6200, f1: 0.7021\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.2419, acc: 0.5673, prec: 0.8021, rec: 0.6345, f1: 0.7085\n",
      "  Val   → loss: 0.2775, acc: 0.5624, prec: 0.8020, rec: 0.6297, f1: 0.7055\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.2259, acc: 0.5720, prec: 0.8020, rec: 0.6415, f1: 0.7128\n",
      "  Val   → loss: 0.2901, acc: 0.5658, prec: 0.8070, rec: 0.6277, f1: 0.7062\n",
      "Epoch 00005: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.2064, acc: 0.5822, prec: 0.8058, rec: 0.6493, f1: 0.7191\n",
      "  Val   → loss: 0.2877, acc: 0.5567, prec: 0.7893, rec: 0.6443, f1: 0.7094\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.1957, acc: 0.5918, prec: 0.8068, rec: 0.6599, f1: 0.7260\n",
      "  Val   → loss: 0.3001, acc: 0.5598, prec: 0.7940, rec: 0.6389, f1: 0.7081\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.1899, acc: 0.6022, prec: 0.8078, rec: 0.6720, f1: 0.7337\n",
      "  Val   → loss: 0.3247, acc: 0.5590, prec: 0.7936, rec: 0.6424, f1: 0.7100\n",
      "Epoch 00008: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.1788, acc: 0.6193, prec: 0.8117, rec: 0.6904, f1: 0.7462\n",
      "  Val   → loss: 0.3238, acc: 0.5541, prec: 0.7842, rec: 0.6480, f1: 0.7096\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train → loss: 0.1738, acc: 0.6255, prec: 0.8135, rec: 0.6979, f1: 0.7512\n",
      "  Val   → loss: 0.3491, acc: 0.5444, prec: 0.7760, rec: 0.6510, f1: 0.7080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:  48%|████▊     | 53/111 [00:14<00:13,  4.35it/s]"
     ]
    }
   ],
   "source": [
    "from torchvision.models import googlenet, GoogLeNet_Weights\n",
    "for backbone_name in ('resnet50','inception_v3','googlenet'):\n",
    "    print(f\"\\n Backbone: {backbone_name.upper()}\")\n",
    "    model     = MultiModalNet(backbone_name).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.BCELoss()\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5,\n",
    "                                                     patience=2, verbose=True)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(f\"Epoch {epoch}/{epochs}\")\n",
    "        tr_loss, tr_metrics = train_epoch(model, train_loader, optimizer, criterion)\n",
    "        val_loss, val_metrics = eval_epoch(model, val_loader, criterion, desc=\"Val\")\n",
    "        print(f\"  Train → loss: {tr_loss:.4f}, acc: {tr_metrics['accuracy']:.4f}, prec: {tr_metrics['precision']:.4f}, rec: {tr_metrics['recall']:.4f}, f1: {tr_metrics['f1']:.4f}\")\n",
    "        print(f\"  Val   → loss: {val_loss:.4f}, acc: {val_metrics['accuracy']:.4f}, prec: {val_metrics['precision']:.4f}, rec: {val_metrics['recall']:.4f}, f1: {val_metrics['f1']:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f\"best_{backbone_name}.pt\")\n",
    "            print(\"Saved best model.\")\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    model.load_state_dict(torch.load(f\"best_{backbone_name}.pt\"))\n",
    "    test_loss, test_metrics = eval_epoch(model, test_loader, criterion, desc=\"Test\")\n",
    "    print(f\"→ Test → loss: {test_loss:.4f}, acc: {test_metrics['accuracy']:.4f}, prec: {test_metrics['precision']:.4f}, rec: {test_metrics['recall']:.4f}, f1: {test_metrics['f1']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
