{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations saved to output_annotations.json\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def convert_to_list(item):\n",
    "    \"\"\"\n",
    "    Recursively convert NumPy arrays or scalars (or any nested structure) into native Python types.\n",
    "    \"\"\"\n",
    "    if isinstance(item, np.generic):  # For numpy scalars (np.int32, np.float64, etc.)\n",
    "        return item.item()\n",
    "    elif isinstance(item, np.ndarray):\n",
    "        return item.tolist()\n",
    "    elif isinstance(item, (list, tuple)):\n",
    "        return [convert_to_list(x) for x in item]\n",
    "    elif isinstance(item, dict):\n",
    "        return {k: convert_to_list(v) for k, v in item.items()}\n",
    "    else:\n",
    "        return item\n",
    "\n",
    "def flatten_nested(data):\n",
    "    \"\"\"\n",
    "    Recursively flattens any nested list/tuple/ndarray structure and returns a list of strings.\n",
    "    \"\"\"\n",
    "    if isinstance(data, (list, tuple, np.ndarray)):\n",
    "        flattened = []\n",
    "        for item in data:\n",
    "            flattened.extend(flatten_nested(item))\n",
    "        return flattened\n",
    "    else:\n",
    "        return [str(data)]\n",
    "\n",
    "def list_to_string(data):\n",
    "    \"\"\"\n",
    "    Flattens the nested data structure and returns a comma-separated string.\n",
    "    \"\"\"\n",
    "    flattened = flatten_nested(data)\n",
    "    return \", \".join(flattened)\n",
    "\n",
    "def process_split(struct_data, base_path):\n",
    "    annotations_by_image = defaultdict(list)\n",
    "    num_images = struct_data.shape[1]  # Assuming struct_data is (1, N)\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        entry = struct_data[0, i]\n",
    "        folder = entry[\"folder\"][0]\n",
    "        filename = entry[\"filename\"][0]\n",
    "        image_path = os.path.join(base_path, folder, filename)\n",
    "        \n",
    "        persons = entry[\"person\"]\n",
    "        if persons.shape[0] == 1:\n",
    "            persons = persons[0]  # Flatten the array if needed\n",
    "        \n",
    "        for j in range(persons.shape[0]):\n",
    "            person_entry = persons[j]\n",
    "            bbox = person_entry[\"body_bbox\"][0]\n",
    "            discrete = person_entry[\"annotations_categories\"][0]\n",
    "            continuous = person_entry[\"annotations_continuous\"][0]\n",
    "            # Omitting gender and age as requested\n",
    "            \n",
    "            annotations_by_image[image_path].append({\n",
    "                \"bbox\": bbox,\n",
    "                \"discrete\": discrete,\n",
    "                \"continuous\": continuous\n",
    "            })\n",
    "    return annotations_by_image\n",
    "\n",
    "def clamp_bbox(x1, y1, x2, y2, image_shape):\n",
    "    \"\"\"\n",
    "    Clamp the bounding box coordinates to be within the image bounds.\n",
    "    Returns a tuple (x1, y1, x2, y2) if valid after clamping, or None if it becomes degenerate.\n",
    "    \"\"\"\n",
    "    h, w = image_shape[:2]\n",
    "    x1_clamped = max(0, x1)\n",
    "    y1_clamped = max(0, y1)\n",
    "    x2_clamped = min(w, x2)\n",
    "    y2_clamped = min(h, y2)\n",
    "    if x1_clamped >= x2_clamped or y1_clamped >= y2_clamped:\n",
    "        return None\n",
    "    return (x1_clamped, y1_clamped, x2_clamped, y2_clamped)\n",
    "\n",
    "def load_and_process_images(annotations_by_image):\n",
    "    output_annotations = []  # List to store valid annotations\n",
    "    image_id_mapping = {}    # Mapping image_path to a unique image_id\n",
    "    current_id = 0\n",
    "\n",
    "    for image_path, annotations in annotations_by_image.items():\n",
    "        if image_path not in image_id_mapping:\n",
    "            image_id_mapping[image_path] = current_id\n",
    "            current_id += 1\n",
    "        image_id = image_id_mapping[image_path]\n",
    "\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Error loading image: {image_path}\")\n",
    "            continue\n",
    "\n",
    "        for annotation in annotations:\n",
    "            bbox = annotation[\"bbox\"]\n",
    "            # Convert bbox coordinates to integers\n",
    "            x1, y1, x2, y2 = map(int, bbox)\n",
    "            # Clamp bounding box coordinates instead of skipping\n",
    "            clamped = clamp_bbox(x1, y1, x2, y2, image.shape)\n",
    "            if clamped is None:\n",
    "                print(f\"Clamped bbox is degenerate for image {image_path}: {bbox}\")\n",
    "                continue\n",
    "            cx1, cy1, cx2, cy2 = clamped\n",
    "\n",
    "            output_annotations.append({\n",
    "                \"image_id\": image_id,\n",
    "                \"image_path\": image_path,\n",
    "                \"bbox\": [cx1, cy1, cx2, cy2],\n",
    "                \"discrete\": convert_to_list(annotation[\"discrete\"]),\n",
    "                \"continuous\": convert_to_list(annotation[\"continuous\"])\n",
    "            })\n",
    "\n",
    "    return output_annotations\n",
    "\n",
    "import os   # make sure os is imported at top\n",
    "\n",
    "# Set the paths to your .mat file and the base directory for images.\n",
    "mat_file  = os.path.join(\"annotations\", \"Annotations.mat\")\n",
    "base_path = \"emotic\"\n",
    "\n",
    "# Load the .mat file data.\n",
    "mat_data = sio.loadmat(mat_file)\n",
    "\n",
    "all_annotations = {}\n",
    "\n",
    "# Process each split (train, val, test) and store the results.\n",
    "for split in ['train', 'val', 'test']:\n",
    "    struct_data           = mat_data[split]\n",
    "    annotations_by_image  = process_split(struct_data, base_path)\n",
    "    split_annotations     = load_and_process_images(annotations_by_image)\n",
    "    all_annotations[split]= [convert_to_list(ann) for ann in split_annotations]\n",
    "\n",
    "# Create a new dictionary with flattened string values for discrete and continuous labels.\n",
    "json_data = {}\n",
    "for split, anns in all_annotations.items():\n",
    "    json_data[split] = []\n",
    "    for ann in anns:\n",
    "        ann[\"discrete\"]   = list_to_string(ann[\"discrete\"])\n",
    "        ann[\"continuous\"] = list_to_string(ann[\"continuous\"])\n",
    "        json_data[split].append(ann)\n",
    "\n",
    "# Dump the final annotations to a JSON file in Code/\n",
    "json_file = \"output_annotations.json\"\n",
    "with open(json_file, mode='w', encoding='utf-8') as f:\n",
    "    json.dump(json_data, f, indent=4)\n",
    "\n",
    "print(f\"Annotations saved to {json_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote new_splits → train_val_test_split.json\n"
     ]
    }
   ],
   "source": [
    "## import json\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# 1) Load the existing annotations (only 'train' split)\n",
    "with open(\"output_annotations.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "train_anns = data[\"train\"]  # list of dicts\n",
    "\n",
    "# 2) Group annotations by image_id\n",
    "anns_by_image = defaultdict(list)\n",
    "for ann in train_anns:\n",
    "    anns_by_image[ann[\"image_id\"]].append(ann)\n",
    "\n",
    "# 3) Randomly split image_ids into 70/15/15\n",
    "image_ids = list(anns_by_image.keys())\n",
    "random.shuffle(image_ids)  # no seed → non‑deterministic\n",
    "\n",
    "n = len(image_ids)\n",
    "n_train = int(n * 0.70)\n",
    "n_val   = int(n * 0.15)\n",
    "# ensure all images accounted for\n",
    "n_test  = n - n_train - n_val\n",
    "\n",
    "train_ids = image_ids[:n_train]\n",
    "val_ids   = image_ids[n_train : n_train + n_val]\n",
    "test_ids  = image_ids[n_train + n_val : ]\n",
    "\n",
    "# 4) Flatten back into three annotation lists\n",
    "new_splits = {\"train\": [], \"val\": [], \"test\": []}\n",
    "\n",
    "for img_id in train_ids:\n",
    "    new_splits[\"train\"].extend(anns_by_image[img_id])\n",
    "for img_id in val_ids:\n",
    "    new_splits[\"val\"].extend(anns_by_image[img_id])\n",
    "for img_id in test_ids:\n",
    "    new_splits[\"test\"].extend(anns_by_image[img_id])\n",
    "\n",
    "# 5) Write out combined JSON\n",
    "with open(\"train_val_test_split.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_splits, f, indent=4)\n",
    "\n",
    "print(\"Wrote new_splits → train_val_test_split.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved updated annotations with multi-hot vectors to 'train_val_test_split_with_multihot.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define the 7 universal emotion categories in your desired order\n",
    "universal_categories = [\n",
    "    \"Anger\",\n",
    "    \"Disgust\",\n",
    "    \"Fear\",\n",
    "    \"Happiness\",\n",
    "    \"Sadness\",\n",
    "    \"Surprise\",\n",
    "    \"Contempt\"\n",
    "]\n",
    "\n",
    "# Mapping from each of the 26 EMOTIC labels to one of the 7 universal categories\n",
    "emotic_to_universal = {\n",
    "    \"Anger\":       \"Anger\",\n",
    "    \"Annoyance\":   \"Anger\",\n",
    "    \"Disapproval\": \"Anger\",\n",
    "    \n",
    "    \"Aversion\":    \"Disgust\",\n",
    "    \"Fear\":        \"Fear\",\n",
    "\n",
    "    \"Affection\":   \"Happiness\",\n",
    "    \"Confidence\":  \"Happiness\",\n",
    "    \"Engagement\":  \"Happiness\",\n",
    "    \"Esteem\":      \"Happiness\",\n",
    "    \"Excitement\":  \"Happiness\",\n",
    "    \"Happiness\":   \"Happiness\",\n",
    "    \"Pleasure\":    \"Happiness\",\n",
    "    \"Peace\":       \"Happiness\",\n",
    "\n",
    "    \"Sadness\":     \"Sadness\",\n",
    "    \"Suffering\":   \"Sadness\",\n",
    "    \"Fatigue\":     \"Sadness\",\n",
    "    \"Pain\":        \"Sadness\",\n",
    "\n",
    "    \"Surprise\":            \"Surprise\",\n",
    "    \"Anticipation\":        \"Surprise\",\n",
    "    \"Doubt/Confusion\":     \"Surprise\",\n",
    "\n",
    "    \"Disconnection\":   \"Contempt\",\n",
    "    \"Disquietment\":    \"Contempt\",\n",
    "    \"Embarrassment\":    \"Contempt\",\n",
    "    \"Sensitivity\":      \"Contempt\",\n",
    "    \"Sympathy\":         \"Contempt\",\n",
    "    \"Yearning\":         \"Contempt\"\n",
    "}\n",
    "\n",
    "\n",
    "def build_multihot(discrete_str):\n",
    "    \"\"\"\n",
    "    Convert the comma-separated EMOTIC labels into a 7-dimensional multi-hot vector.\n",
    "    \"\"\"\n",
    "    # Split, strip whitespace\n",
    "    labels = [lbl.strip() for lbl in discrete_str.split(\",\") if lbl.strip()]\n",
    "    # Start with zeros\n",
    "    vec = [0] * len(universal_categories)\n",
    "    # For each emotic label, map to universal and set that index to 1\n",
    "    for lbl in labels:\n",
    "        uni = emotic_to_universal.get(lbl)\n",
    "        if uni is None:\n",
    "            # Warn on unknown labels\n",
    "            print(f\"Warning: '{lbl}' not found in mapping; skipping.\")\n",
    "            continue\n",
    "        idx = universal_categories.index(uni)\n",
    "        vec[idx] = 1\n",
    "    return vec\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Input and output JSON files\n",
    "    in_json  = \"train_val_test_split.json\"\n",
    "    out_json = \"train_val_test_split_with_multihot.json\"\n",
    "\n",
    "    # Load existing splits\n",
    "    with open(in_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Process each split\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        for entry in data.get(split, []):\n",
    "            discrete_str = entry.get(\"discrete\", \"\")\n",
    "            entry[\"multi_hot\"] = build_multihot(discrete_str)\n",
    "\n",
    "    # Save updated JSON\n",
    "    with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    print(f\"Saved updated annotations with multi-hot vectors to '{out_json}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
